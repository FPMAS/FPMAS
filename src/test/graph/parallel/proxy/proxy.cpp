#include "gtest/gtest.h"
#include "graph/parallel/proxy/proxy.h"
#include "graph/parallel/zoltan/zoltan_utils.h"

#include "mpi.h"

using FPMAS::graph::proxy::Proxy;
using FPMAS::graph::zoltan::utils::read_zoltan_id;
using FPMAS::graph::zoltan::utils::write_zoltan_id;

using FPMAS::graph::proxy::obj_size_multi_fn;
using FPMAS::graph::proxy::pack_obj_multi_fn;

TEST(Mpi_ProxyTest, build_proxy_test) {
	int local_rank;
	MPI_Comm_rank(MPI_COMM_WORLD, &local_rank);
	Proxy proxy(local_rank);

	ASSERT_EQ(local_rank, proxy.getLocalProc());

}

TEST(Mpi_ProxyTest, build_proxy_with_ranks) {
	int global_size;
	MPI_Comm_size(MPI_COMM_WORLD, &global_size);
	int current_rank;
	MPI_Comm_rank(MPI_COMM_WORLD, &current_rank);

	if(global_size == 1) {
		Proxy p (current_rank, {current_rank});
	}
	else if(global_size >= 2) {
		if(!(global_size % 2 == 1 && current_rank == (global_size-1))) {
			if(current_rank % 2 == 0) {
				Proxy p (current_rank, {current_rank, (current_rank + 1) % global_size});
			} else {
				Proxy p (current_rank, {(global_size + current_rank - 1) % global_size, current_rank});
			}
		}
		else {
			// MPI requirement : all processes must call MPI_Comm_create, that
			// is called to build MpiCommunicators used by proxies
			Proxy p (current_rank, {current_rank});
		}
	}
}

class Mpi_ZoltanProxyTest : public ::testing::Test {
	protected:

		static void SetUpTestSuite() {
		}

		Proxy* proxy;
		int rank;

		// Migration
		unsigned int transfer_global_ids[6];
		int sizes[3];
		int idx[3];
		char buf[249];

		// Error code
		int err;

		void SetUp() override {
			MPI_Comm_rank(MPI_COMM_WORLD, &rank);
			proxy = new Proxy(rank);

			proxy->setOrigin(0ul, rank);
			proxy->setLocal(0ul);

			proxy->setOrigin(1ul, 12);
			proxy->setLocal(1ul);

			proxy->setOrigin(2ul, rank);
			proxy->setCurrentLocation(2ul, 25);
		}

		void write_migration_sizes() {
			// Transfer nodes 0 and 85250
			write_zoltan_id(0ul, &transfer_global_ids[0]);
			write_zoltan_id(1ul, &transfer_global_ids[2]);
			write_zoltan_id(2ul, &transfer_global_ids[4]);

			obj_size_multi_fn(
					proxy,
					2,
					0,
					3,
					transfer_global_ids,
					nullptr,
					sizes,
					&err
					);
		}

		void write_communication_buffer() {
			// Automatically generated by Zoltan in a real use case
			idx[0] = 0;
			idx[1] = sizes[0] + 1;
			idx[2] = idx[1] + sizes[1] + 1;

			// Unused
			int dest[3];

			pack_obj_multi_fn(
					proxy,
					2,
					0,
					3,
					transfer_global_ids,
					nullptr,
					dest,
					sizes,
					idx,
					buf,
					&err
					);
		}

		void TearDown() override {
			delete proxy;
		}

		static void TearDownTestSuite() {
		}
};

TEST_F(Mpi_ZoltanProxyTest, obj_size_multi_fn_test) {
	write_migration_sizes();
	int rank_str_size = std::to_string(rank).size() + 1;
	ASSERT_EQ(sizes[0], rank_str_size);
	ASSERT_EQ(sizes[1], rank_str_size);
	ASSERT_EQ(sizes[2], 3); // loc = "25"

}

TEST_F(Mpi_ZoltanProxyTest, pack_obj_multi_fn_test) {
	write_migration_sizes();
	write_communication_buffer();

	std::string currentRank = std::to_string(rank);
	ASSERT_STREQ(currentRank.c_str(), &buf[idx[0]]);
	ASSERT_STREQ(currentRank.c_str(), &buf[idx[1]]);
	ASSERT_STREQ("25", &buf[idx[2]]);
}

using FPMAS::graph::proxy::unpack_obj_multi_fn;

TEST_F(Mpi_ZoltanProxyTest, unpack_obj_multi_test) {
	write_migration_sizes();
	write_communication_buffer();
	// Fake proxy
	Proxy p(rank+1);

	unpack_obj_multi_fn(
		&p,
		2,
		3,
		transfer_global_ids,
		sizes,
		idx,
		buf,
		&err);

	ASSERT_EQ(p.getCurrentLocation(0ul), rank);
	ASSERT_EQ(p.getCurrentLocation(1ul), rank);
	ASSERT_EQ(p.getCurrentLocation(2ul), 25);
}

class Mpi_SyncProxyTest : public ::testing::Test {
	protected:
		Proxy* proxy;
		int size;
		int rank;
		int previous_rank;
		int next_rank;

		void SetUp() override {
			MPI_Comm_rank(MPI_COMM_WORLD, &rank);
			MPI_Comm_size(MPI_COMM_WORLD, &size);

			// Each nodes are built such as id = origin, for id in [0,size[
			//
			// Each local proc owns the node rank+1 where rank is the rank
			// of the local proc. This ensures that each node is located
			// exactly on one proc.
			//
			// Then we manually build proxy so that :
			//  - if rank is odd, information about the node with this
			//  proxy as origin should be up to date on the proxy where the
			//  node currently lives, so no update needs to be pushed.
			//  - if rank is even, the same information is outdated, so
			//  information needs to be pushed from the proxy where the node
			//  lives to this proxy.
			//  - an entry for previous_rank is kept on each proxy,
			//  voluntarily unitialized, so that this information must be
			//  fetched by each process. At the end, it should be updated
			//  and correct.

			proxy = new Proxy(rank);
			previous_rank = (size+rank-1) % size;
			next_rank = (rank+1) % size;

			// Initializes proxy entries
			proxy->setOrigin(previous_rank, previous_rank);
			proxy->setCurrentLocation(previous_rank, -1);
			proxy->setOrigin(rank, rank);
			proxy->setOrigin(next_rank, next_rank);

			if(rank % 2 == 0) {
				if(rank == 0 && size % 2 == 1) {
					// Special case, when we have an odd number of procs.
					// Normally, previous rank is odd, so the origin
					// information of node rank should not be up to date so
					// that updates will be pushed from the previous odd proxy.
					// But if size = 5 for example, previous_rank=4 of
					// proxy 0 is even
					// so updates won't be push. So for this particular
					// case, we "manually" set the correct location.
					proxy->setCurrentLocation(rank, previous_rank);
				} else {
					// Outdated information
					proxy->setCurrentLocation(rank, next_rank);
				}
				proxy->setLocal(next_rank, true);
			}
			else {
				// Up to date information, so previous_rank proxy does not
				// have to push information
				proxy->setCurrentLocation(rank, previous_rank);

				// Outdated information for the next_rank proxy :
				// information needs to be pushed from this odd proxy to
				// the next proxy
				proxy->setLocal(next_rank);
			}

		}

		void TearDown() override {
			delete proxy;
		}

};

TEST_F(Mpi_SyncProxyTest, synchronize_proxy_test) {
	proxy->synchronize();

	ASSERT_EQ(proxy->getCurrentLocation(previous_rank), (size+previous_rank-1) % size);
	ASSERT_EQ(proxy->getCurrentLocation(rank), previous_rank);
	ASSERT_EQ(proxy->getCurrentLocation(next_rank), rank);

};
